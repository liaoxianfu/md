### 进度汇报

本周阅读论文《Deep Neural Network for YouTube Recommendation》大致理解了了其模型思想，下周打算基于这个模型和上周的阿里DIN模型对比微调，因为YouTube训练数据量较大，但是一般的网站时达不到这么大数据量的，因此打算在该模型中试试能不能引入小样本的算法并在现有的一些公开数据集上进行实验。

### **一、系统概览**

在工业界工作的同学对下图的系统划分并不陌生。整个推荐系统分为candidate generation和Ranking两个阶段。Matching阶段通过i2i/u2i/u2u/user profile等方式“粗糙”的召回候选商品，Matching阶段视频的数量是百级别了；Ranking阶段对Matching后的视频采用更精细的特征计算user-item之间的排序分，作为最终输出推荐结果的依据。

![img](https://pic3.zhimg.com/80/v2-533f102bd97b2b8cdf25639cfb0ab3e9_720w.png)

之所以把推荐系统划分成Matching和Ranking两个阶段，主要是从性能方面考虑的。Matching阶段面临的是百万级视频，单个视频的性能开销必须很小；而Ranking阶段的算法则非常消耗资源，不可能对所有视频都算一遍，实际上即便资源充足也完全没有必要，因为往往来说通不过Matching粗选的视频，大部分在Ranking阶段排名也很低。接下来分别从Matching和Ranking阶段展开介绍。



### **二、Matching**

#### **2.1 问题建模**

我们把推荐问题建模成一个“超大规模多分类”问题。即在时刻![[公式]](https://www.zhihu.com/equation?tex=t)，为用户![[公式]](https://www.zhihu.com/equation?tex=U)（上下文信息![[公式]](https://www.zhihu.com/equation?tex=C)）在视频库![[公式]](https://www.zhihu.com/equation?tex=V)中精准的预测出视频![[公式]](https://www.zhihu.com/equation?tex=i)的类别（每个具体的视频视为一个类别，![[公式]](https://www.zhihu.com/equation?tex=i)即为一个类别），用数学公式表达如下：

![img](https://picb.zhimg.com/80/v2-adde74b978b971e588c002038c390e0b_720w.png)

很显然上式为一个softmax多分类器的形式。向量![[公式]](https://www.zhihu.com/equation?tex=u%5Cin+R%5EN)是<user, context>信息的高纬“embedding”，而向量![[公式]](https://www.zhihu.com/equation?tex=v_%7Bj%7D%5Cin+R%5EN)则是视频 j 的embedding向量。所以DNN的目标就是在用户信息和上下文信息为输入条件下学习用户的embedding向量![[公式]](https://www.zhihu.com/equation?tex=u)。用公式表达DNN就是在拟合函数![[公式]](https://www.zhihu.com/equation?tex=u+%3D+f_%7BDNN%7D%28user_info%2C+context_info%29)。

#### **2.2 模型架构**

![img](https://pic4.zhimg.com/80/v2-7f97ddd40285e08b64546e3a54a5d64a_720w.png)

整个模型架构是包含三个隐层的DNN结构。输入是用户浏览历史、搜索历史、人口统计学信息和其余上下文信息concat成的输入向量；输出分线上和离线训练两个部分。



#### **2.3 主要特征**

类似于word2vec的做法，每个视频都会被embedding到固定维度的向量中。用户的**观看视频历史**则是通过变长的视频序列表达，最终通过**加权平均（可根据重要性和时间进行加权）**得到固定维度的watch vector作为DNN的输入。

**除历史观看视频外的其他signal：**

其实熟悉Skip-Gram方法的同学很容易看出来，2.1把推荐问题定义为“超大规模多分类”问题的数学公式和word2vec的Skip-Gram方法的公式基本相同，所不同的是user_vec是通过DNN学习到的，而**引入DNN的好处则是任意的连续特征和离散特征可以很容易添加到模型当中**。同样的，推荐系统常用的矩阵分解方法虽然也能得到user_vec和item_vec，但同样是不能嵌入更多feature。

主要特征：

- **历史搜索query**：把历史搜索的query分词后的token的embedding向量进行加权平均，能够反映用户的整体搜索历史状态
- **人口统计学信息**：性别、年龄、地域等
- **其他上下文信息**：设备、登录状态等

*“Example Age” （视频上传时间）特征*

视频网络的时效性是很重要的，每秒YouTube上都有大量新视频被上传，而对用户来讲，哪怕牺牲相关性代价，用户还是更倾向于更新的视频。当然我们不会单纯的因为一个视频新就直接推荐给用户。

因为机器学习系统在训练阶段都是利用过去的行为预估未来，因此通常对过去的行为有个隐式的bias。视频网站视频的分布是高度非静态（non-stationary）的，但我们的推荐系统产生的视频集合在视频的分布，基本上反映的是训练所取时间段的平均的观看喜好的视频。因此我们我们把样本的 “age” 作为一个feature加入模型训练中。从下图可以很清楚的看出，加入“example age” feature后和经验分布更为match。

![img](https://pic3.zhimg.com/80/v2-83f523875baab074b340b6ccea2eba02_720w.png)





### **三、Ranking**

Ranking阶段的最重要任务就是精准的预估用户对视频的喜好程度。不同于Matching阶段面临的是百万级的候选视频集，Ranking阶段面对的只是百级别的商品集，因此我们可以*使用更多更精细的feature*来刻画视频（item）以及用户与视频（user-item）的关系。比如用户可能很喜欢某个视频，但如果list页的用的“缩略图”选择不当，用户也许不会点击，等等。

此外，Matching阶段的来源往往很多，没法直接比较。Ranking阶段另一个关键的作用是能够把不同来源的数据进行有效的ensemble。

在目标的设定方面，单纯CTR指标是有迷惑性的，有些靠关键词吸引用户高点击的视频未必能够被播放。因此设定的目标基本与期望的观看时长相关，具体的目标调整则根据线上的A/B进行调整。

#### **3.1 模型架构**

Ranking阶段的模型和Matching基本相似，不同的是training最后一层是一个weighted LR层，而serving阶段激励函数用的是![[公式]](https://www.zhihu.com/equation?tex=e%5E%7Bx%7D+)，具体在3.3阐述。

![img](https://picb.zhimg.com/80/v2-33f93002d2d7f42f50e617e03ef659bd_720w.png)

#### **3.2 特征表达**



**a). Feature Engineering：**

尽管深度学习在图像、语音和NLP等场景都能实现end-to-end的训练，没有了人工特征工程工作。然而在搜索和推荐场景，我们的很难吧原始数据直接作为FNN的输入，*特征工程仍然很重要*。而特征工程中最难的是如何建模用户时序行为（***temporal sequence of user actions***），并且关联这些行为和要rank的item。

我们发现**最重要的Signal是描述用户与商品本身或相似商品之间交互的Signal**，这与Facebook在14年提出LR+GBDT模型的paper中得到的结论是一致的。比如我们要度量用户对视频的喜欢，可以考虑用户与视频所在频道间的关系：

- **数量特征**：浏览该频道的次数？
- **时间特征**：比如最近一次浏览该频道距离现在的时间？

这两个连续特征的最大好处是具备非常强的泛化能力。另外除了这两个偏正向的特征，用户对于视频所在频道的一些PV但不点击的行为，即**负反馈Signal同样非常重要**。



另外，我们还发现，把Matching阶段的信息传播到Ranking阶段同样能很好的提升效果，比如推荐来源和所在来源的分数。

**b). Embedding Categorical Features**

NN更适合处理连续特征，因此稀疏的特别是高基数空间的离散特征需要embedding到稠密的向量中。每个维度（比如query/user_id）都有独立的embedding空间，一般来说空间的维度基本与log(去重后值得数量)相当。实际并非为所有的id进行embedding，比如视频id，只需要按照点击排序，选择top N视频进行embedding，其余置为0向量。而对于像“过去点击的视频”这种multivalent特征，与Matching阶段的处理相同，进行加权平均即可。

另外一个值得注意的是，同维度不同feature采用的相同ID的embedding是共享的（比如“过去浏览的视频id” “seed视频id”），这样可以大大加速训练，但显然输入层仍要分别填充。



#### **3.4 不同隐层的实验**

下图的table1是离线利用hold-out一天数据在不同NN网络结构下的结果。如果用户对模型预估高分的反而没有观看，我们认为是预测错误的观看时长。weighted, per-user loss就是预测错误观看时长占总观看时长的比例。

我们对网络结构中隐层的宽度和深度方面都做了测试，从下图结果看增加隐层网络宽度和深度都能提升模型效果。而对于1024-->512-->256这个网络，测试的不包含归一化后根号和方式的版本，loss增加了0.2%。而如果把weighted LR替换成LR，效果下降达到4.1%。



![img](https://pic4.zhimg.com/80/v2-05b935a5fba84dac4f575dd679ddd66a_720w.png)