
[TOC]
### 论文《Learning Dynamic Routing for Semantic Segmentation》翻译



#### 摘要

近年来，大量手工构建和搜索的网络被应用于语义分割。然而，以前的工作打算在预定义的静态体系结构(如FCN、U-Net和DeepLab系列)中处理各种尺度的输入。这篇论文提出了一种缓解语义表示尺度差异的方法--动态路由。这种框架生成依赖于数据的路由，以适应每幅图像的尺度分布。为此，提出了一种称为软控门（soft conditional gate）的可微门控函数来动态选择尺度变换路径。此外，通过预先设置门控函数的约束条件可以使用端到端的方式进一步的降低计算成本。我们进一步放宽了网络级路由空间，以支持每次转发中的多路径传播和跳过连接，从而带来可观的网络容量。为了证明动态特性的优越性，我们比较了几种静态体系结构，它们可以作为路由空间中的特例建模。在Cityscape和Pascal VOC 2012上进行了大量的实验，以说明动态框架的有效性。代码地址 https://github.com/yanwei-li/DynamicRouting

#### 1、介绍



语义分割是计算机视觉领域最基本也是最具挑战性的任务之一，其目的是为每个像素赋予语义类别。语义分割的问题之一来自于输入之间巨大的尺度差异，例如微小的对象实例和充满图片的背景事物。此外，较大的分布方差给特征表达和关系建模带来了困难。传统的方法试图通过设计良好的网络体系结构来解决这一问题。例如多分辨率融合采用针对细节的feature maps和long-range dependencies 被捕获通过全局上下文建模。随着NAS网络的发展，开始致力于研究自动搜索的语义分割结构。

然而，不管是传统的基于人工设计的还是基于NAS的网络都只是试图用一个单一的网络结构表现所有实例。这样缺乏对真实环境中不同尺寸分布表现的适应性。图1中给出了一个例子，其中实例的规模变化很大。为此，需要一个更可定制的网络来适应每个图像的比例变化。

在这篇论文中，我们对于语义分割提出了一个概念意义上新颖的模型，称之为动态路由。动态路由在推理过程中生成依赖于数据的转发路径，这意味着特定的网络结构会随着输入的不同而不同。通过这种方法我们使用自定义的特征转换可以将不同尺度的实例（或背景）分配到相应的分辨率阶段。如图1所示，具有不同尺度分布的输入图像将选择不同的路径进行特征变换。目前已经有一些对于目标检测的动态网络研究通过dropping blocks或pruning channels。 与他们不同的是，我们的工作侧重于语义表示和旨在缓解尺寸差异和提高模型效率。

在传统的动态图像分类方法中，路由空间通常局限于分辨率下降的管道，这将不能满足语义分割的要求。我们从Auto-DeepLab[22]的搜索空间中得到启发，开发了一种新的路由空间，它包含几个独立的单元，以提高容量。具体地说，与AutoDeepLab不同，多路径传播和跳过连接被证明在语义分割中是非常重要的，在推理过程中的每一次转发中都启用了多路径传播和跳过连接。因此几种经典的网络体系结构可以作为比较的特例包括在内（图3）。在动态路由中，设计了一种与数据相关的路由门，被称为软控门，被设计为根据输入图像选择每条路径。根据建议的路由门，可以单独考虑每个基本单元以及分辨率变换路径。此外，所提出的路由门可以被描述为端到端优化的可微模块。因此，给定有限的计算预算(例如，FLOP)，几乎没有贡献的单元将被即时丢弃。

![image-20200701182832150](D:\MarkDown\DeepLearning\img\image-20200701182832150.png)

图1.给定具有不同规模分布的输入，所提出的动态路由将选择相应的转发路径。例如，大型实例1(A)的体系结构可以忽略低级特征。小尺度对象1(B)可以依赖于低级别细节以及较高分辨率。而混合比例1(C)将同时享受这两种连接模式。图表中的红线表示它们之间的差异。

整个方法被称为动态路由，可以很轻易的实现语义化分割。为了阐述它在性能和效率上相对于固定结构的优势，我们在4.3节进行了详细的研究和分析。进一步报告了在两个著名的数据集上的实验结果，即Cityspace[9]和Pascal VOC 2012[11]。通过简单的规模变换模块，所提出的动态路由获得了与最新方法相当的结果，但消耗的资源要少得多。



#### 2、相关工作

传统的语义分割研究主要集中在根据人的经验设计微妙的网络体系结构。随着NAS网络的发展有许多的网络尝试自动进行搜索静态网络。与以往的工作不同的是，动态路由是根据输入选择最合适的尺度变换。很少有人研究。在此，我们首先回顾了人工设计的语义分割体系结构。然后介绍了基于NAS的方法。最后，对动态网络的研究现状进行了回顾。

##### 2.1 手工挑选的结构

近些年手工挑选的结构得到了广泛的研究。在语义分割中有FCN 、U-Net、Conv-DeConv ，SegNet等。基于良好的FCN和U型结构已经提出了许多工作来捕获更大的接收场，或者建立像素级关系来实现对全局上下文进行建模。由于密集预测的高资源消耗，为了提高效率，人们提出了一些轻量级的体系结构，包括ICNet[42]和BiSeNet[40]。总体而言，手工构建的体系结构旨在利用静态网络中不同阶段的多尺度功能，而不是适应动态输入。

##### 2.2 基于NAS的处理

近年来，神经体系结构搜索(NAS)被广泛应用于自动网络结构设计[45，27，23，2，13，7]。当涉及到特定领域时，有几种方法试图寻找更适合语义分割的有效体系结构。具体地说，陈等人。[3]搜索多尺度模块以取代ASPP[5]块。此外，Nekrasov et.al.。[25]采用基于NAS的方法研究解码器中辅助信元的路由类型。最近，Auto-DeepLab[22]被提出从密集连接的搜索空间中搜索单个路径。与基于NAS的搜索单个体系结构然后对其进行重新训练的方法不同，提出的动态路由无需搜索即可动态生成前向路径。

##### 2.3  动态网络

动态网络是近年来计算机视觉领域的研究热点，它通过调整网络结构来适应相应的输入。传统的图像分类主要通过dropping blocks 或者pruning  channels 进行有效的推理。例如 在MSDNet中存在一种早期的策略进行资源效率高的对象识别，该策略比较容易对输入进行分类并在较早期间进行输出。SkipNet尝试使用RL-based门控网络跳过卷积块。然而，动态路由在尺度变换方面的研究很少，特别是在语义分割方面。为了充分利用网络的动态性，本文提出了一种端到端的动态路由框架，以缓解输入之间的规模差异。

![image-20200703104512327](D:\MarkDown\DeepLearning\img\image-20200703104512327.png)

图2 面向语义分割的动态路由框架  图片的左边: 具有L层，最大下采样为32。为了稳定，开始的STEM和最终的上采样是固定的。虚线表示动态路由可选的路径。图片右边：cell级别的动态路由处理. 给定来自前一层的输入总和，我们首先使用软控门$Soft$   $Conditional$  $Gate$生成激活权重。相应权重大于零的路径被标记为激活，这将被选择用于特征转换。有关网络的详细信息见3.4节。

#### 3、学习动态路由

与静态网络相比，动态路由在资源消耗相同的情况下在网络容量和性能上具有优势。在本节中，我们首先介绍设计的路由空间。然后，详细阐述了动态路由框架和约束机制。体系结构详细信息将在本节末尾提供。

##### 3.1、路由空间

为了释放动态路由的潜力，我们在相邻层之间提供具有一些先验约束的全连接路径，例如，单元之间的上采样或下采样跨度，如图2所示。具体来说按照网络设计中的一般做法，网络的开始是一个固定的3层“STEM”块，将分辨率降低到1/4尺度。在此基础上，设计了L层动态路由空间，称为路由空间。在路由空间中，相邻的Cell之间的比例因子被限制为2，这在基于RestNet的方法中被广泛采用。因此，最小比例设置为1/32。在这些约束条件下，每层候选的数目最多为4个，每个候选图像有3条尺度变换路径，即上采样、保持分辨率和下采样。在每个候选者内部基本单元被设计用于特征聚合，基本门被用于路径选择。如图2所示。逐层上采样模块固定在网络末端以生成预测。有关动态路由过程的更多详细信息，请参见3.2小节。

与Auto-DeepLab[22]在推理阶段每个节点只选择一条特定路径不同，我们进一步放宽了路由空间，支持每个候选节点的多路径路由和跳过连接。有了更一般的空间，许多流行的体系结构可以表示为特例，如图3所示。在4.3节给出了进一步的定量比较并且展示了动态路由的优越性。

##### 3.2、路由处理

在给定具有多个独立节点的路由空间的情况下，我们在每个节点内部分别采用一个基本单元和一个对应的门来聚合多尺度特征和选择路由路径。这一过程在图2中给出了简要说明。更具体的说我们首先聚合来自$l-1$层具有不同空间大小的三个输入(也就是 $s/2、s、2s$) 分别表示为$Y_{s/2}^{l-1}、Y_{s}^{l-1}、Y_{2s}^{l-1}$因此,可以将第l层的输入$X_s^l$表示为
$$
X_s^l=Y_{s/2}^{l-1}+Y_{s}^{l-1}+Y_{2s}^{l-1}
$$
然后聚合的输入将用于$Cell$ $Gate$的内部转换.



###### 3.2.1 操作Cell

对于输入数据$X_s^l\in \mathbb{R}^{B*C*W*H}$,我们们在每个单元中采用了广泛使用的分离卷积的堆栈和恒等式映射,没有使用多余的技巧.特别的是,隐藏状态$H_s^l\in\mathbb{R}^{B*C*W*H}$可以表示为
$$
H_s^l=\sum_{O^i\in{o}}O^i(X_s^l)\quad\quad\quad\quad\quad\quad\quad   (1)
$$
o代表可操作集合,包括SepConv3x3和identity mapping.这里对每个cell采用基本的特征融合. 然后会生成特征图$H_s^{l}$将根据激活因子$\alpha_s^l$变换到不同的尺度.这一过程将会在下一节详细说明.此外在4.4.1节对不同的cell组件进行比较.



###### 3.3.2 Soft Conditional Gate 软控门

每条路径的路由概率由门函数生成，如图2的右图所示。更详细的说,我们在门中采用轻量化卷积运算来学习依赖数据的向量$G_s^l$

![image-20200703171059084](D:\MarkDown\DeepLearning\img\image-20200703171059084.png)



其中F(·，·)表示卷积函数，σ表示RELU激活，N和G分别表示 batch normalization 和全局平均池化 (global average pooling )。ω和β都是卷积参数。与传统的基于RL的方法[36，38，34]采用策略梯度更新代理进行离散路径选择不同，本文提出了可区分路由的软控门,为此,对于特征向量$G_s^l\in\mathbb{R}^{B*3*1*1}$激活函数被设计为
$$
\delta(.)=max(0,Tanh(.)) \quad \quad (3)
$$
因此,激活因子$\alpha_s^l\in\mathbb{R}^{B*3*1*1}$可以通过$\delta(G_s^l)$计算出来,$\alpha_s^l$区间为[0,1)当$\alpha_{s\to j}^l=0$时从s->j的路径就会被关闭.所有$\alpha_{s \to j}^l>0$的路径都会被保留下来,允许多路径传播. 更具体的来说,在第B批次中的第b个输入将会生成$\alpha_{b,s\to j}^l\in \mathbb{R}^{1*1*1*1}$ 这意味着路由路径随输入或所谓的数据相关而变化。这样,每条路径都可以被单独考虑而不是选择一条相对重要的路径进行传播.此外在4.4.2节还研究了不同的激活函数.

利用所提出的激活函数δ，训练过程中从尺度s到j∈{s/2，s，2s}的变换可以表示为
$$
Y_j^l = \alpha_{s\to j}^l \Tau_{s\to j}(H_s^l) \quad \quad (4)
$$
这里$\Tau_{s\to j}$代表从尺度s到j的尺度变换(包括上采样和下采样)因此,根据激活因子$\alpha_{s}^l$ $G_s^l$的参数可以在反向传播中被优化同时 只需要保持一条路径即可.(也就是 $\sum_j \alpha_{s\to j}^l>0$)

在推理阶段,如果所有的路径都被标记为关闭,Cell中的操作会被丢弃来节省计算空间.根据等式1.这一过程可以概括为



![image-20200703183605488](D:\MarkDown\DeepLearning\img\image-20200703183605488.png)



![image-20200703171310777](D:\MarkDown\DeepLearning\img\image-20200703171310777.png)

图3 节选的之前的网络结构  利用设计的路由空间可以用相似的形式表示几种经典的体系结构.例如 FCN-32s 图a U-Net 图b DeepLab V3 图c HRNetV2 图d 和Auto-Deeplab 图e



##### 3.3 预算约束



考虑到现实场景中有限的计算资源，我们考虑了预算约束，以实现高效的动态路由。我们定义$C$作为与预定义操作 相关联的计算成本例如 FLOPs.根据等式1,2和4 我们表示在第s层的尺寸和第l层的layer预期的花费为:

![image-20200703184500173](D:\MarkDown\DeepLearning\img\image-20200703184500173.png)

其中$Cell_s^l \quad Gate_s^l \quad Trans_s^l$分别表示Cell、Gate、Scale内部变换的操作、更进一步，整个路由空间可以通过下式进行计算
$$
C(Space)=\sum_{l\le L}\sum_{s\le1/4}C(Node_s^l)
$$
然后，我们将资源花费C(Space)在loss函数中进行表示 进行端到端的优化。

![image-20200703185204461](D:\MarkDown\DeepLearning\img\image-20200703185204461.png)

用C表示整个路由空间真实的计算成本，µ∈[0，1]表示设计衰减系数。使用不同的µ，每次传播中选择的路由将自适应地限制在相应的预算内。不同预算约束下的网络性能将在4.4.3节进行讨论。

总体而言，网络权重和软控门能够在统一的框架下使用联合损失函数L进行优化。

![image-20200703185756006](D:\MarkDown\DeepLearning\img\image-20200703185756006.png)

其中$L_N和L_C$分别表示整个网络的算是函数和资源花费，λ1和λ2分别用于平衡网络预测和资源成本预期的优化过程。



##### 3.4 网络的详细结构

从宏观的角度来看，我们将路由空间深度设置为16或33，与广泛使用的ResNet-50和ResNet-101[16]中的相同，即图2中的总层L=16或33。与基于RestNet的网络相比，这种设置能够带来便利，我们的网络可以直接使用建议的路由空间进行构建。

当在网络中涉及到微节点的时候，我们在STEM块中采用3个SepConv3x3，这些卷积中共计有64个filter,对所有s->s/2的路径使用一个步长为2的1x1卷积核进行卷积，即降低了特征分辨率又将filter翻倍。在s->2s连接上使用1x1卷积核进行双线性上采样，即可以提高分辨率又可以减少filter

此外，设计了一个简单的解码器来融合最终预测的特征，在图2中，最终预测表示为网络末端的灰色节点。具体来说就是在解码器中使用带有双线性上采样的1*1卷积融合不同的尺寸。并且将尺度为1/4预测进行上采样生成最终的结果。卷积中的权重采用正态分布进行初始化，等式2中的偏置$\beta_s^l$通过实现设置为常数1.5。当给定预先约束，我们将等式2中的输入$X_s^l$ 通过4次减少资源消耗的门控函数进行下采样。除此之外，输入$X_s^l$的分辨率保持不变。

#### 4、实验

在本节中我们首先介绍数据集和实现动态路由的具体细节。然后我们在Cityscapes 数据集做了大量的abundant ablation研究，并对各组成部分的作用进行了详细的分析。最后与一些使用 Cityscapes  和 PASCAL VOC 2012 的数据集基准进行比较，以此来说明我们提出方法的有效性和高效性。

##### 4.1 数据集

**Cityscapes**: Cityscapes数据集是是一个被广泛使用的城市场景理解数据集，它包含19个用于评价的类别。该数据集包含5000个大小为1024×2048的精细注释，这些注释可分为2975、500和1525幅图像，分别用于训练、验证和测试。它还有另外2万张用于训练的粗略注释，我们的实验中没有使用这些注释。

**PASCAL VOC**： 我们在Pascal VOC 2012数据集[11]上进行了实验，该数据集包括20个对象类别和一个背景类。原始数据集分别包含1464、1449和1456个用于训练、验证和测试的图像。这里，我们使用[14]提供的扩充数据，产生10582幅图像用于训练。



##### 4.2 实现细节

为了便于复现，我们报告了优化的细节信息。为了获得更好的表现，等式10的$\lambda_1$设为1.0 ,$\lambda_2$根据4.4.3节中不同的约束分类进行设置。网络优化采用SGD，衰减为$1e^{-4}$动量为0.9.类似于[5，40，31]，我们采用‘ploy’计划 初始化速率乘以$(1-\frac{iter}{iter_{max}})^{power}$ 在每次迭代的时候设置power为0.9。在训练阶段，我们随机反转和进行0.5到倍的缩放。根据实验设置施加不同的初始速率。具体地说，在从头开始训练和使用ImageNet[10]进行预训练时，我们分别将初始率设置为0.05和0.02。对于Cityscapes[9]，我们从8个随机的768×768个图像作物中构造每个小批次用于训练。对于Pascal VOC 2012[11]，在每次迭代中采用16个随机的512×512图像裁剪进行优化。



##### 4.3 动态路由

为了论证动态路由的优越性，我们将动态网络与现有的几种体系结构和从路由空间采样的静态路由进行了比较。特别地，传统的人工设计的网络以及$ searched$  $  architectures$，包括FCN-32S[24]、U-NET[28]、DeepLabV3[5]、HRNetV2[32]和AutoDeepLab[22]，在路由空间中以类似的连接模式建模，如图3所示。为了公平比较，我们通过赋予等式9中不同的预算的损失函数进行约束使得计算开销与这些方法保持一致。因此可以生成三种类型的动态网络（具体细节参见4.4.3小节）在表1分别表示为 Dynamic-A, B, 和 C.与手工设计和搜索的体系结构相比，提出的动态路由在相同的代价下获得了更好的性能。例如，给定45G、55G和65G左右的预算约束，动态A、B和C分别比DeepLabV3、U-Net和HRNetV2获得5.8%、2.2%和2.1%的增加。

在此基础上，提取保留了95%以上正向推理的动态网络基本路径，形成相应的公共网络。通用网络连接模式见图4.在表1中我们进一步的比较了通用结构的动态网络(Common-A, B, and C)。具体来说，在使用动态路由框架下的动态网络在每个预算约束下都比普通静态网络具有更好的性能。这些性能比较见表1.



我们观察到通用的网络连接与已知的几种体系结构相似，例如人工设计的U-Net[28]和基于NAS的Auto-DeepLab[22]。特别是在网络的前端采用下采样操作，在网络的后端优先使用上采样操作。此外，对象细节需要低层阶段的高分辨率特征（见图1）可能会获得更好的表现。



![image-20200704170211029](D:\MarkDown\DeepLearning\img\image-20200704170211029.png)

表1 在Cityscapes验证集中与经典的结构进行比较。‘Dynamic’代表使用动态路由。A、B和C代表在4.4.3节中使用的不同的预算。‘Common’代表相应动态网络的通用连接方式。$FLOPs_{Avg}$、$FLOPs_{M ax}$和$ FLOPs_{Min}$分别代表网络中FLOPs平均、最大、最小值.所有的结构都是从设计的路由空间中设计抽取出来的并在相同的设置下自动进行评估。

##### 4.4 组件的详细分析

为了揭示所提出的方法中每个组件的作用，在本节中我们将一步步的分解我们的方法。首先我们将详细讨论cell中的组件，然后研究软控门中的激活函数。最后将进一步说明不同资源预算的效果。

###### 4.4.1 Cell组件

为了与以前的网络结构进行公平比较，每个cell中只有基本的卷积操作和identity mapping，没有其他华而不实的操作。表2是与一些经典操作包括（ BottleNeck [16], MBConv [29], and SepConv [8] ）的实验结果。我们发现动态网络在堆叠两个SepConv3×3进行特征变换时性能最好，heavier operations不会带来更多的增益。我们猜测这可能归结于路由结构相比于heavier operations扮演着更重要的角色。事实上，当分辨率为1/4时，我们也对较大的核(例如SepConv5×5)进行了实验，但是只增加了0.2% ,因此为了简单起见本文仍然采用SepConv3x3。

![image-20200704171306338](D:\MarkDown\DeepLearning\img\image-20200704171306338.png)

图4 从表2中具有不同预算约束的动态模型中提取的Common-A、B、C的网络体系结构，在图4(a)、(b)、(c)中进行可视化。





![image-20200704174504013](D:\MarkDown\DeepLearning\img\image-20200704174504013.png)

表2  在Cityscapes 验证集中使用不同的cell组件比较结果。‘×2’和‘×3’分别表示进行2和3次SepConv3×3堆积。由于动态路由data-dependent的性质，我们只报告了平均的FLOPs。



![image-20200704174517941](D:\MarkDown\DeepLearning\img\image-20200704174517941.png)

表3  Cityscapes验证集中不同激活函数的比较。由于动态路由data-dependent的性质，我们只报告了平均的FLOPs。

![image-20200704180333902](D:\MarkDown\DeepLearning\img\image-20200704180333902.png)

表4  Cityscapes验证集中不同资源预算比较。在3.3小节$\lambda_2$和$\mu$代表预算约束系数，由于动态路由data-dependent的性质，我们只报告了平均的FLOPs。

###### 4.4.2 激活函数

在3.2.2节中 我们进一步的比较了一些广泛使用的激活函数在软控门中的表现。首先，路由空间中的所有路径都被无差别地固定，以形成我们的baseline，也就是表3中的'Fix'。然后在等式3中的激活函数$\delta$被替换成表3中的激活函数。我们发现函数max(0,Tanh)相比于其他的激活函数取得了更好的表现。更重要的是使用Softmax激活函数，它在每个cell中会考虑三个路径相比于单独考虑的激活函数要差，例如Sigmoid和max(0,Tanh)。这意味着每条路径在软空门中都应该单独考虑。然后，所有$\alpha>0$的路径都应该在前向推理中被保留。具体见3.2.2节。



###### 4.4.3 资源预算

通过设计的门控函数，我们通过调整$\lambda_2$和$\mu$来提供不同的资源预算。在表4中通过给不同的预算约束产生了不同的动态网络(Dynamic-A, B, and C).与没有资源预算约束的网络Dynamic Raw相比，在性能损失不大的情况下Dynamic-C ，计算开销降低了**55.7%**同时Dynamic-C 在有效性和效率上仍然优于全连接的Network-Fix。在更强的约束下，资源开销在Dynamic-A中能否进一步下降到37.6%。

此外，我们在图5中给出了路由激活概率分布。很明显，大多数路径倾向于保留在Dynamic-Raw中。如果给定资源预算，将丢弃不同比例的路线，这可以从图5中的分配中了解到。因此，动态路由会在推理过程中剔除无用的路径和cell。我们通过表1发现在$FLOPs_{Max}$和$FLOP_{Min}$之间的差距小于10%,这可能归结于预算约束的影响。事实上，我门也尝试了不同类型的coefficient of variation 来增大差异。但是效果比较差。

##### 4.5 在Cityscapes数据集上实验

我们在仅使用了精确注释的Cityspace数据集。在表5我们比较了几个训练好的数据集在验证集上。所提出的方法在不同的情况下取得了一致的改进效果。使用Scheduled Drop Path和ImageNet预训练可以进一步的提高动态网络（L=16）的性能。表6中给出了与前任工作的比较。在资源开销相近的情况下，我们提出的动态网络在验证集上达到了78.6%的mIoU比精心设计的BiSenet提高了3.8%。动态网络(L=33)采用简单的比例变换没有华而不实的操作，性能与最先进的网络相当但是资源消耗成本要低的多。此外，结合上下文捕获模块（如PSP块），该方法有了进一步的改进，在Cityspace数据集上取得了80.7%的mIoU。

![image-20200704201408551](D:\MarkDown\DeepLearning\img\image-20200704201408551.png)

图5 动态网络中路由激活概率的分布。在Dynamic-Raw中大多数路径在没有限制的情况下被保留。在给定资源的情况下Dynamic-A, B, and C不同比例的路由会被关闭，

![image-20200704201743729](D:\MarkDown\DeepLearning\img\image-20200704201743729.png)

表5 使用单一尺度和没有翻转在Cityspace验证集上的不同设置的实验。‘ImageNet’代表使用ImageNet进行预训练。‘SDP’ 代表 Scheduled Drop Path.。

![image-20200704202146969](D:\MarkDown\DeepLearning\img\image-20200704202146969.png)

表6 在Cityspace数据集上与之前的工作进行比较。$mIoU_{test}$和$mIoU_{val}$分别代表测试集和验证集。测试集采用了多尺度和翻转的策略但是在验证集没有使用这些策略。我们报告的FLOPs是使用输入尺寸为1024x2048.

![image-20200704202816329](D:\MarkDown\DeepLearning\img\image-20200704202816329.png)

表7 在PASCAL VOC2012数据集上与之前的工作进行比较。$mIoU_{test}$和$mIoU_{val}$分别代表测试集和验证集。测试集采用了多尺度和翻转的策略但是在验证集没有使用这些策略。我们报告的FLOPs是使用输入尺寸为512x512.



##### 4.6 在PASCAL  VOC数据集上实验

我们进一步与类似的方法(在COCO[21]数据集上预训练)在Pascal VOC 2012[11]数据集上进行了比较，这些方法关注的是计算开销相当的体系结构设计。特别的是我们提出的得到在准确性和效率上都超过了Auto-DeepLab,后者需要花费3GPUdays在architecture searching，如表7所示。与基于MobileNet的DeepLabV3相比，动态网络使用相似的资源花费得到了更好的表现。



#### 5 总结

在这项工作中我们对语义分割任务提出了动态路由。与以往工作的关键不同之处在于，我们根据每幅图像的尺度分布来生成依赖于数据的前向路径。为此，提出了一种端到端的选择变换路径的软条件门，在给定资源预算的条件下学习丢弃无用的操作以提高效率。对于extensive ablation 的研究已经证明了动态网络相对于静态网络的优越性，动态网络可以在设计的路由空间中进行建模。在CitySees和Pascal VOC 2012上的实验证明了该方法的有效性，该方法的性能与现有技术相当，但消耗的计算资源要少得多。



#### Acknowledgement

This work was supported by National Key Research and
Development Program of China 2018YFD0400902 and Na-
tional Natural Science Foundation of China 61573349.



#### References

[1] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla.
Segnet: A deep convolutional encoder-decoder architecture
for image segmentation. TPAMI, 2017. 1, 2
[2] Han Cai, Ligeng Zhu, and Song Han. Proxylessnas: Direct
neural architecture search on target task and hardware. In
ICLR, 2019. 2
[3] Liang-Chieh Chen, Maxwell Collins, Y ukun Zhu, George
Papandreou, Barret Zoph, Florian Schroff, Hartwig Adam,
and Jon Shlens. Searching for efficient multi-scale architec-
tures for dense image prediction. In NeurIPS, 2018. 1, 2
[4] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos,
Kevin Murphy, and Alan L Y uille. Deeplab: Semantic image
segmentation with deep convolutional nets, atrous convolu-
tion, and fully connected crfs. TPAMI. 2
[5] Liang-Chieh Chen, George Papandreou, Florian Schroff, and
Hartwig Adam. Rethinking atrous convolution for semantic
image segmentation. arXiv:1706.05587, 2017. 2, 4, 5, 6, 8
[6] Liang-Chieh Chen, Y ukun Zhu, George Papandreou, Florian
Schroff, and Hartwig Adam. Encoder-decoder with atrous
separable convolution for semantic image segmentation. In
ECCV, 2018. 1, 2, 8
[7] Xin Chen, Lingxi Xie, Jun Wu, and Qi Tian. Progressive dif-
ferentiable architecture search: Bridging the depth gap be-
tween search and evaluation. In ICCV, 2019. 2
[8] Franc ¸ois Chollet. Xception: Deep learning with depthwise
separable convolutions. In CVPR, 2017. 6
[9] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo
Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe
Franke, Stefan Roth, and Bernt Schiele. The cityscapes
dataset for semantic urban scene understanding. In CVPR,2016.2, 5, 7

[10] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In CVPR, 2009. 5, 8
[11] Mark Everingham, Luc V an Gool, Christopher KI Williams,
John Winn, and Andrew Zisserman. The pascal visual object
classes (voc) challenge. IJCV, 2010. 2, 5, 8
[12] Jun Fu, Jing Liu, Haijie Tian, Y ong Li, Y ongjun Bao, Zhiwei
Fang, and Hanqing Lu. Dual attention network for scene
segmentation. In CVPR, 2019. 2
[13] Zichao Guo, Xiangyu Zhang, Haoyuan Mu, Wen Heng,
Zechun Liu, Yichen Wei, and Jian Sun.  Single path
one-shot neural architecture search with uniform sampling.
arXiv:1904.00420, 2019. 2
[14] Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev,
Subhransu Maji, and Jitendra Malik. Semantic contours from
inverse detectors. In ICCV, 2011. 5
[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Delving deep into rectifiers: Surpassing human-level perfor-
mance on imagenet classification. In ICCV, 2015. 5
[16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In CVPR,2016 5, 6, 7
[17] Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens
van der Maaten, and Kilian Q Weinberger. Multi-scale dense

networks for resource efficient image classification. In ICLR,2018 2
[18] Zilong Huang, Xinggang Wang, Lichao Huang, Chang
Huang, Y unchao Wei, and Wenyu Liu. Ccnet: Criss-cross
attention for semantic segmentation. In ICCV, 2019. 2
[19] Alexander Kirillov, Ross Girshick, Kaiming He, and Piotr
Dollár. Panoptic feature pyramid networks. In CVPR, 2019.
1, 8
[20] Ji Lin, Y ongming Rao, Jiwen Lu, and Jie Zhou. Runtime
neural pruning. In NeurIPS, 2017. 2
[21] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence
Zitnick. Microsoft coco: Common objects in context. In
ECCV, 2014. 8
[22] Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig
Adam, Wei Hua, Alan L Y uille, and Li Fei-Fei. Auto-
deeplab: Hierarchical neural architecture search for semantic
image segmentation. In CVPR, 2019. 1, 2, 3, 4, 5, 6, 8
[23] Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts:
Differentiable architecture search. In ICLR, 2019. 2, 3, 4
[24] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
convolutional networks for semantic segmentation.  In
CVPR, 2015. 1, 2, 4, 5, 6
[25] Vladimir Nekrasov, Hao Chen, Chunhua Shen, and Ian Reid.
Fast neural architecture search of compact semantic segmen-
tation models via auxiliary cells. In CVPR, 2019. 1, 2
[26] Hyeonwoo Noh, Seunghoon Hong, and Bohyung Han.
Learning deconvolution network for semantic segmentation.
In ICCV, 2015. 2
[27] Hieu Pham, Melody Y Guan, Barret Zoph, Quoc V Le, and
Jeff Dean. Efficient neural architecture search via parameter
sharing. In ICML, 2018. 2
[28] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net:
Convolutional networks for biomedical image segmentation.
In MICCAI, 2015. 1, 2, 4, 5, 6
[29] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zh-
moginov, and Liang-Chieh Chen. Mobilenetv2: Inverted
residuals and linear bottlenecks. In CVPR, 2018. 6, 7
[30] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy
Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outra-
geously large neural networks: The sparsely-gated mixture-
of-experts layer. In ICLR, 2017. 7
[31] Lin Song, Yanwei Li, Zeming Li, Gang Y u, Hongbin Sun,
Jian Sun, and Nanning Zheng.  Learnable tree filter for
structure-preserving feature transform. In NeurIPS, 2019.1, 2, 5
[32] Ke Sun, Yang Zhao, Borui Jiang, Tianheng Cheng, Bin Xiao,
Dong Liu, Yadong Mu, Xinggang Wang, Wenyu Liu, and
Jingdong Wang. High-resolution representations for labeling
pixels and regions. arXiv:1904.04514, 2019. 1, 4, 5, 6
[33] Ravi Teja Mullapudi, William R Mark, Noam Shazeer, and
Kayvon Fatahalian. Hydranets: Specialized dynamic archi-
tectures for efficient inference. In CVPR, 2018. 2
[34] Tom V eniat and Ludovic Denoyer. Learning time/memory-
efficient deep architectures with budgeted super networks. In
CVPR, 2018. 4

[35] Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaim-
ing He. Non-local neural networks. In CVPR, 2018. 1
[36] Xin Wang, Fisher Y u, Zi-Yi Dou, Trevor Darrell, and
Joseph E Gonzalez. Skipnet: Learning dynamic routing in
convolutional networks. In ECCV, 2018. 2, 4
[37] Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang,
Fei Sun, Yiming Wu, Y uandong Tian, Peter V ajda, Yangqing
Jia, and Kurt Keutzer. Fbnet: Hardware-aware efficient con-
vnet design via differentiable neural architecture search. In
CVPR, 2019. 4
[38] Zuxuan Wu, Tushar Nagarajan, Abhishek Kumar, Steven
Rennie, Larry S Davis, Kristen Grauman, and Rogerio Feris.
Blockdrop: Dynamic inference paths in residual networks.
In CVPR, 2018. 2, 4
[39] Zhonghui Y ou, Kun Yan, Jinmian Ye, Meng Ma, and Ping
Wang. Gate decorator: Global filter pruning method for ac-
celerating deep convolutional neural networks. In NeurIPS,2019 2
[40] Changqian Y u, Jingbo Wang, Chao Peng, Changxin Gao,
Gang Y u, and Nong Sang. Bisenet: Bilateral segmenta-
tion network for real-time semantic segmentation. In ECCV,1，2, 5, 8
[41] Changqian Y u, Jingbo Wang, Chao Peng, Changxin Gao,
Gang Y u, and Nong Sang. Learning a discriminative feature
network for semantic segmentation. In CVPR, 2018. 2
[42] Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping
Shi, and Jiaya Jia. Icnet for real-time semantic segmentation
on high-resolution images. In ECCV, 2018. 2
[43] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang
Wang, and Jiaya Jia. Pyramid scene parsing network. In
CVPR, 2017. 1, 2, 8
[44] Hengshuang Zhao, Yi Zhang, Shu Liu, Jianping Shi, Chen
Change Loy, Dahua Lin, and Jiaya Jia. Psanet: Point-wise
spatial attention network for scene parsing. In ECCV, 2018.1, 2
[45] Barret Zoph and Quoc V Le. Neural architecture search with
reinforcement learning. In ICLR, 2017. 2
[46] Barret Zoph, Vijay V asudevan, Jonathon Shlens, and Quoc V
Le. Learning transferable architectures for scalable image
recognition. In CVPR, 2018. 3, 8

