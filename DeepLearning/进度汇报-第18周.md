本周继续上周的NLP相关内容同时学习了语义分割的相关内容。阅读论文《Fully Convolutional Networks for Semantic Segmentation》



**论文相关**

### 一、摘要

​		① 作者认为通过端到端和像素到像素超过了最先进的语义分割技术。②建立全卷积网络通过有效的推理和学习实现任意大小图片的输入和产生对应大小的输出图片。③修改现在的分类网络（AlexNet、VGG、GoogleNet）的变为全卷积网络。定义了一个跳跃的架构可以结合来自深层和浅层的特征信息从而产生准确精细的分割。④ 成果:在VOC数据集上准确率达到了62.2% 相对其他提升了20%。

### 二、引言

​	卷积神经网络在识别领域发展迅速，不仅在全图识别上的准确率大大提升而且在结构化输出的局部任务上取得了进步。包括在目标检测，关键点预测和局部通信等问题。

 	识别的下一步是从粗糙到精细也就是对每一个像素进行预测。在这之前也有人使用卷积网络进行语义分割，通过将每一个像素进行标记分类从而形成一个封闭的对象或者区域，但是有一个缺点就是预测物体的位置。

​	作者在语义分割上实现了一个“端到端”，“像素到像素”的全卷积网络。此网络无需附加更多的装置就可以实现当前的最先进的语义分割技术。FCN能够输入任意尺度的图片并进行预测输出。学习和推理能在全图通过密集的前馈计算和反向传播一次执行。网内上采样层能在像素级别预测和通过下采样池化学习。

![image-20200621154719796](D:\MarkDown\DeepLearning\img\image-20200621154719796.png)

### 三、全卷积网络

​		卷积网络的每层数据都是$h*w*d$。h和w是空间维度,d是特征或通道维数。第一层是像素尺寸为h*w、颜色通道数为d的图像。高层中的locations和图像中它们连通的locations相对应，被称为接收域。

​		卷积网是以平移不变形作为基础的。其基本组成部分(卷积，池化和激励函数)作用在局部输入域，只依赖相对空间坐标。在特定层记$X_{ij}$、$Y_{ij}$为下一层的输入，计算公式如下:

​		![image-20200621162847641](D:\MarkDown\DeepLearning\img\image-20200621162847641.png)

![image-20200621163001854](D:\MarkDown\DeepLearning\img\image-20200621163001854.png)

​		当一个普通深度的网络计算一个普通的非线性函数，一个网络只有这种形式的层计算非线性滤波，我们称之为深度滤波或全卷积网络。(注： 其实就是将之前的全连接层替换为卷积层，最后输出的也是卷积层，在Restnet中有实现)。

#### 3.1 修改分类网络为密集预测

​		经典的识别网络，例如LeNet、AlexNet和一些更深的网络表面上采用的是固定的输入尺寸和非空间的输出（注：就是将卷积层转换成全连接层最终输出的预测种类的分类结果）。这些网络的全连接层有着确定的大小位数并丢弃了空间坐标信息。然而，这些全连接层也被看做是覆盖全部输入域的核卷积。需要将它们加入到可以采用任何尺寸输入并输出分类图的全卷积网络中。



![这里写图片描述](D:\MarkDown\DeepLearning\img\20161022115412312.png)

​	这些卷积化模式的空间输出图可以作为一个很自然的选择对于dense问题，比如语义分割。每个输出单元ground truth可用，正推法和逆推法都是直截了当的，都利用了卷积的固有的计算效率(和可极大优化性)。对于AlexNet例子相应的逆推法的时间为单张图像时间2.4ms，全卷积的10*10输出图为37ms，结果是相对于顺推法速度加快了。

#### 3.2  Shift-and-stitch

dense prediction能从粗糙输出中通过从输入的平移版本中将输出拼接起来获得。如果输出是因为一个因子f降低采样率，平移输入的x像素到左边，与像素到下面，一旦对于每个（x,y）满足0<=x  y<=f 处理。处理$f^2$个输入，并将输出交错以便预测他们接受域的中心像素一致。

**详解**(这里作者没有详细解释，网上<a href="https://blog.csdn.net/qinghuaci666/article/details/80833866">查询</a>结果如下)：

假设下采样因子f=2 那么输出为$f^2=4$ 这里的x，y取（`0`,`0`), (`0`,`1`),(`1`,`0`),(`1`,`1`) 



<img src="D:\MarkDown\DeepLearning\img\70.png" alt="img" style="zoom:80%;" />

也就是根据不同的移动规则得出4个不同的输出。进行maxpooling后

<img src="D:\MarkDown\DeepLearning\img\71.png" alt="img" style="zoom:80%;" />

<img src="D:\MarkDown\DeepLearning\img\72.png" alt="img" style="zoom:50%;" />



使用Shift-and-stitch转换增加了$f^2$的代价，在小波领域中有一个多孔算法。考虑一个层（卷积或者池化）中的输入步长s,和后面的滤波权重为f_ij的卷积层（忽略不相关的特征维数）。设置更低层的输入步长到l上采样它的输出影响因子为s。然而，将原始的滤波和上采样的输出卷积并没有产生和shift-and-stitch相同的结果，因为原始的滤波只看得到（已经上采样）输入的简化的部分。

#### 3.3 上采样就是向后卷积

​		另一种连接粗糙输出到dense像素的方法就是插值法。比如，简单的双线性插值计算每个输出$y_{ij}$来自只依赖输入和输出单元的相对位置的线性图最近的四个输入。



### 四、Segmentation架构

​		作者将ILSVRC分类应用到FCNs增大它们用于dense prediction结合网内上采样和像素级损失。通过微调参数进行分割训练。然后够造了一个跳跃的结构来结合浅层信息和深层信息，训了VOC2011数据集,。如下图所示

![image-20200621182952576](D:\MarkDown\DeepLearning\img\image-20200621182952576.png)

#### 4.1、 从分类到dense FCN

​		作者选取了AlexNet、VGG16、GoogleNet作为基础网络。作者发现使用VGG16和19的差别不大，所以选择了16，对于GoogleNet，仅仅使用了最后的loss层并且舍弃了全局平均池化来提高其表现。

​		通过舍弃以上网络的网络头将全连接层转换为卷积层，最后附加了一个1*1*21的卷积层老预测分类。得到的结果如下：

![image-20200621184851653](D:\MarkDown\DeepLearning\img\image-20200621184851653.png)

虽然分类模型表现良好，即使是最坏的情况也能达到75%的准确率，分割网络（FCN-VGG16）表现最好在验证集上达到了平均IU56.0的成绩，在使用额外数据的情况下达到了59.4的成绩。尽管分类的准确率相差不大但是GoogleNet的分割结果表现并不是很好，不能与VGG相比。

#### 4.2 结合是什么和在哪里

​	

​		将一个线划拓扑结构转变成DAG(有向无环图)，并且边界将从更底层向前跳跃到更高（见上的网络结构图）。因为它们只能获取更少的像素点，更精细的尺寸预测应该需要更少的层，所以从更浅的网中将它们输出是有道理的。结合了精细层和粗糙层让模型能做出遵从全局结构的局部预测。

​		从FCN-32s-->16s-->8s通过加深网络以及融合可以从下图与表中看出分割的效果变得更加精细，IU值也更高。

![image-20200621201943445](D:\MarkDown\DeepLearning\img\image-20200621201943445.png)

#### 4.3 实验框架



优化器：使用带动量的SGD，

输入：20张图片/批次 

 学习率$10^{-3} 10^{-4} 10^{-5}$ 对应FCN-AlexNet、 FCN-VGG16和 FCN-GoogLeNet。

动量为0.9 权重衰减为$5^{-4}$、$2^-4$。训练结果如下：

![image-20200621204135600](D:\MarkDown\DeepLearning\img\image-20200621204135600.png)



### 五、结果

​	作者将PASCAL VOC NYUDv2和SIFT Flow这些数据集上进行验证，并统一将这些视为像素预测，都获得了较好的成绩。

![image-20200621205914466](D:\MarkDown\DeepLearning\img\image-20200621205914466.png)



![image-20200621205943609](D:\MarkDown\DeepLearning\img\image-20200621205943609.png)

**NLP相关**：

​	NLP学习了fastText和Glove的相关内容。并利用pytoch使用Glove实现了近义词（英文）

核心代码如下:

```python
a = [key for key in vocab.pretrained_aliases.keys() if "glove" in key]
print(a)
cache_dir = r'F:\DL_dataset\wiki'

glove = vocab.GloVe(name='6B', dim=50, cache=cache_dir)
print(len(glove))

print(glove.stoi['beautiful'], glove.itos[3366])  

def knn(W, x, k):
    # 添加的1e-9是为了数值稳定性
    cos = torch.matmul(W, x.view((-1,))) / (
            (torch.sum(W * W, dim=1) + 1e-9).sqrt() * torch.sum(x * x).sqrt())
    _, topk = torch.topk(cos, k=k)
    topk = topk.cpu().numpy()
    return topk, [cos[i].item() for i in topk]


def get_similar_tokens(query_token, k, embed):
    topk, cos = knn(embed.vectors,
                    embed.vectors[embed.stoi[query_token]], k + 1)
    for i, c in zip(topk[1:], cos[1:]):  # 除去输入词
        print('cosine sim=%.3f: %s' % (c, (embed.itos[i])))
```

