本周研究了阿里推荐系统的DIEN网络模型，并在实验室的机器上进行了训练。DIEN是在原有的DIN网络模型上修改而来的。在淘宝的广告系统中获得了20.7%的系统提升。



### 1、DIN的缺陷

在大多数非搜索电商场景下，用户并不会实时表达目前的兴趣偏好。因此通过设计模型来捕获用户的动态变化的兴趣，是提升CTR预估效果的关键。阿里之前的DIN模型将用户的历史行为来表示用户的兴趣，并强调了用户兴趣的多样性和动态变化性，因此通过attention-based model来捕获和目标物品相关的兴趣。虽然DIN模型将用户的历史行为来表示兴趣，但存在两个缺点：

1）用户的兴趣是不断进化的，而DIN抽取的用户兴趣之间是独立无关联的，没有捕获到兴趣的动态进化性

2）通过用户的显式的行为来表达用户隐含的兴趣，这一准确性无法得到保证。

### 2、DIEN的改进

1）模型关注电商系统中兴趣演化的过程，并提出了新的网络结果来建模兴趣进化的过程，这个模型能够更精确的表达用户兴趣，同时带来更高的CTR预估准确率。

2）设计了兴趣抽取层，并通过计算一个辅助loss，来提升兴趣表达的准确性。

3）设计了兴趣进化层，来更加准确的表达用户兴趣的动态变化性。

### 3、DIEN的模型结构



DIEN如下图所示，在行为层，将行为按照时间进行排序，embeding 层将one-hot 向量b[t]转换为向量e[t]。兴趣提取层找auxiliary loss的帮助下提取每个兴趣状态h[t].在兴趣进化网络，AUGRU模型会对目标的兴趣演变过程进行建模。将最终感兴趣状态H0[T]和剩余特征的嵌入向量连接起来，馈入MLR进行最终CTR预测。

![image-20201030150454420](D:\MarkDown\DeepLearning\img\image-20201030150454420.png)



### 4、模型详解

#### 4.1、兴趣抽取层

在电子商务系统中，用户行为是潜在利益的载体，用户采取一种行为后，利益就会发生变化。在兴趣提取器层，我们从连续的用户行为中提取一系列的兴趣状态。电子商务系统中用户的点击行为非常丰富，即使在很短的时间内，历史行为序列的长度也很长，比如两周。为了在效率和性能之间取得平衡，我们采用GRU对行为之间的依赖关系进行建模，其中GRU的输入是按照行为发生的时间进行排序的。GRU克服了RNN的梯度消失问题，比适用于电子商务系统的LSTM更快。

具体的公式为:


![image-20201030152325390](D:\MarkDown\DeepLearning\img\image-20201030152325390.png)



#### 4.2、GRU门控网络

从DIEN网络的结构模型图可以看到，网络设计了一个二分类模型来计算兴趣抽取的准确性，将用户下一时刻真实的行为e(t+1)作为正例，负采样得到的行为作为负例e(t+1)'，分别与抽取出的兴趣h(t)结合输入到设计的辅助网络中，得到预测结果，并通过loss计算一个辅助的损失.

![image-20201030153637282](D:\MarkDown\DeepLearning\img\image-20201030153637282.png)



#### 4.3、兴趣进化层

兴趣进化层Interest Evolution Layer的主要目标是刻画用户兴趣的进化过程。举个简单的例子：

以用户对衣服的interest为例，随着季节和时尚风潮的不断变化，用户的interest也会不断变化。这种变化会直接影响用户的点击决策。建模用户兴趣的进化过程有两方面的好处：

1）追踪用户的interest可以使我们学习final interest的表达时包含更多的历史信息。

2）可以根据interest的变化趋势更好地进行CTR预测。

而interest在变化过程中遵循如下规律：

1）interest drift：用户在某一段时间的interest会有一定的集中性。比如用户可能在一段时间内不断买书，在另一段时间内不断买衣服。

2）interest individual：一种interest有自己的发展趋势，不同种类的interest之间很少相互影响，例如买书和买衣服的interest基本互不相关。

为了利用这两个时序特征，我们需要再增加一层GRU的变种，并加上attention机制以找到与target AD相关的interest。



#### 4.4、不同的门控网络

GRU with attentional input (AIGRU)

为了在兴趣演化过程中激活相对兴趣，我们提出了一种朴素的方法，称为带注意输入的GRU(AIGRU)。AIGRU使用注意力得分来影响兴趣进化层的输入。
$$
i'_t = h_t*a_t
$$
其中$h_t$是兴趣提取器层GRU的第t个隐含状态，$i'_t$是第二个GRU的输入，用于兴趣进化，∗表示标量向量积。在AIGRU中，相关程度较低的兴趣的规模可以通过注意力得分来缩小。理想情况下，关联度较低的兴趣输入值可以降为零。然而，AIGRU运行得并不是很好。因为即使零输入也会改变GRU的隐藏状态，因此相对兴趣较少也会影响兴趣进化的学习。

Attention based GRU(AGRU)

在问答领域，首次提出了基于注意力的GRU(AGRU)。通过嵌入注意力机制的信息对GRU结构进行改进后，AGRU能够有效地提取复杂查询中的关键信息。受问答系统的启发，我们将AGRU的使用从提取查询中的关键信息转变为在兴趣演化过程中捕捉相对兴趣。具体而言，AGRU使用关注度来代替GRU的更新门，并直接改变隐藏状态。
$$
h'_t=(1-a_t)*h'_t+a_t*\tilde{h'}_t
$$


 GRU with attentional update gate (AUGRU)

虽然Agru可以直接使用注意力分数来控制隐藏状态的更新，但是它使用一个标量(注意力分数为)来替换一个向量(更新门ut)，这忽略了不同维度之间的重要性差异。我们提出了带有注意力更新门的GRU(AUGRU)，将注意力机制与GRU无缝结合
$$
\tilde{u'_t}=a_t*u'_t \\ \\ 
\\
h'_t=(1-\tilde{u'_t})h'_{t-1}+\tilde{u'_t}\tilde{h'_t}
$$






##### 5、实验

#### 5.1、核心代码

GRU门控网络

```python
with tf.name_scope('rnn_1'):

    rnn_outputs,_ = dynamic_rnn(GRUCell(HIDDEN_SIZE),inputs = self.item_his_eb,sequence_length=self.seq_len_ph,dtype=tf.float32,scope='gru1')

    tf.summary.histogram("GRU_outputs",rnn_outputs)

aux_loss_1 = self.auxiliary_loss(rnn_outputs[:,:-1,:],self.item_his_eb[:,1:,:],self.noclk_item_his_eb[:,1:,:],self.mask[:,1:],stag="gru")

self.aux_loss = aux_loss_1
```

辅助loss的计算其实是一个二分类模型

```python
def auxiliary_loss(self,h_states,click_seq,noclick_seq,mask,stag=None):
    mask = tf.cast(mask,tf.float32)
    click_input = tf.concat([h_states,click_seq],-1)
    noclick_input = tf.concat([h_states,noclick_seq],-1)
    click_prop_ = self.auxiliary_net(click_input,stag=stag)[:,:,0]
    noclick_prop_ = self.auxiliary_net(noclick_input,stag=stag)[:,:,0]
    click_loss_ = -tf.reshape(tf.log(click_prop_),[-1,tf.shape(click_seq)[1]]) * mask
    noclick_loss_ = - tf.reshape(tf.log(1.0 - noclick_prop_), [-1, tf.shape(noclick_seq)[1]]) * mask
    loss_ = tf.reduce_mean(click_loss_ + noclick_loss_)
    return loss_

def auxiliary_net(self,input,stag='auxiliary_net'):
    bn1 = tf.layers.batch_normalization(inputs=input, name='bn1' + stag, reuse=tf.AUTO_REUSE)
    dnn1 = tf.layers.dense(bn1, 100, activation=None, name='f1' + stag, reuse=tf.AUTO_REUSE)
    dnn1 = tf.nn.sigmoid(dnn1)
    dnn2 = tf.layers.dense(dnn1, 50, activation=None, name='f2' + stag, reuse=tf.AUTO_REUSE)
    dnn2 = tf.nn.sigmoid(dnn2)
    dnn3 = tf.layers.dense(dnn2, 2, activation=None, name='f3' + stag, reuse=tf.AUTO_REUSE)
    y_hat = tf.nn.softmax(dnn3) + 0.00000001
    return y_hat
```



DINE网络

```python
def build_fcn_net(self,inp,use_dice=False):
    bn1 = tf.layers.batch_normalization(inputs=inp,name='bn1')
    dnn1 = tf.layers.dense(bn1,200,activation=None,name='f1')
    if use_dice:
        dnn1 = dice(dnn1,name='dice_1')
    else:
        dnn1 = prelu(dnn1,'prelu1')
    dnn2 = tf.layers.dense(dnn1,80,activation=None,name='f2')
    if use_dice:
      dnn2 = dice(dnn2,name='dice_2')
    else:
        dnn2 = prelu(dnn2,name='prelu2')
    dnn3 = tf.layers.dense(dnn2,2,activation=None,name='f3')
    self.y_hat = tf.nn.softmax(dnn3) + 0.00000001
    with tf.name_scope('Metrics'):
        ctr_loss = -tf.reduce_mean(tf.log(self.y_hat) * self.target_ph)
        self.loss = ctr_loss
        if self.use_negsampling:
            self.loss += self.aux_loss
        tf.summary.scalar('loss',self.loss)
        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)
        self.accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.round(self.y_hat),self.target_ph),tf.float32))
        tf.summary.scalar('accuracy',self.accuracy)
    self.merged = tf.summary.merge_all()
```





训练过程

![image-20201030191317104](D:\MarkDown\DeepLearning\img\image-20201030191317104.png)



