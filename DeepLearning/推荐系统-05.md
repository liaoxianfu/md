本周阅读论文《Product-based Neural Networks for User Response Prediction》 针对直接把Embedding之后的特征输入到神经网络中进行计算对特征的交叉组合不充分而提出来的。也是对特征的组合做文章的一种方法。



### 摘要

预测用户响应(如点击量和转换率)是非常重要的，它在许多Web应用中都有应用，包括推荐系统、Web搜索和在线广告。这些应用程序中的数据大多是分类的，包含多个字段；典型的表示是通过一次编码将其转换为高维稀疏二进制特征表示。面对数据的极端稀疏性，传统的模型可能会限制其从数据中挖掘浅层模式的能力，即低阶特征组合。另一方面，由于特征空间巨大，像深度神经网络这样的深度模型不能直接应用于高维输入。本文提出了一种基于乘积的神经网络(PNN)，其中嵌入层用于学习分类数据的分布式表示，乘积层用于捕捉域间类别之间的交互模式，而完全连通层用于探索高阶特征交互。我们在两个大规模真实广告点击数据集上的实验结果表明，PNNS在各种度量上的性能都一致优于最先进的模型。



### 模型介绍



PNN，全称为Product-based Neural Network，认为在embedding输入到MLP之后学习的交叉特征表达并不充分，提出了一种product layer的思想，既基于乘法的运算来体现体征交叉的DNN网络结构，如下图：

![img](https:////upload-images.jianshu.io/upload_images/4155986-9867a7134749f48e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

#### **输出层**

 输出层很简单，将上一层的网络输出通过一个全链接层，经过sigmoid函数转换后映射到(0,1)的区间中，得到我们的点击率的预测值：


$$
\hat{y}=\sigma{W_3l_2+b_3}
$$


#### **l2层**

 根据l1层的输出，经一个全链接层 ，并使用relu进行激活，得到我们l2的输出结果：


$$
l_2=relu(w_2l_1+b_2)
$$


#### **l1层**

 l1层的输出由如下的公式计算：


$$
l_1 = relu(l_z+l_p+b_1)
$$


重点马上就要来了，我们可以看到在得到l1层输出时，我们输入了三部分，分别是lz，lp 和 b1，b1是我们的偏置项，这里可以先不管。lz和lp的计算就是PNN的精华所在了。我们慢慢道来

#### **Product Layer**

product思想来源于，在ctr预估中，认为特征之间的关系更多是一种and“且”的关系，而非add"加”的关系。例如，性别为男且喜欢游戏的人群，比起性别男和喜欢游戏的人群，前者的组合比后者更能体现特征交叉的意义。

product layer可以分成两个部分，一部分是线性部分lz，一部分是非线性部分lp。二者的形式如下：

Product layer部分的思想是认为特征之间的关系是and“且”的一种关系，而非add"加"的关系。以往的方法中特征之间都是

$$
w_i ∗ x_i + w_j ∗ x_j 
$$

的组合方式，这种组合方式过于简单而且是不能凸显出特征之间紧密关系。举个例子：性别为男且喜欢打游戏的人 和 性别为男和喜欢打游戏的人，两者表达的是不同的意思。前者把特征更加细化，相当于抽取的特征更加“明显”或者"精细"，但是后者抽取的特征还是比较跨宽泛的表示。因此后者更能体现特征交叉组合的意义。
  再看上图，product layer部分包含两部分，第一部分是z，第二部分是p。虽然这一层的特征都是圆圈来表示，但是意义却大不相同。首先看z部分，这一块是线性部分，其实就相当与把Embedding层的特征拿过来，组成一个向量即可。

IPNN的示意图如下：

![img](https:////upload-images.jianshu.io/upload_images/4155986-efc8f371d4e694a4.png?imageMogr2/auto-orient/strip|imageView2/2/w/740/format/webp)

IPNN中p的计算方式如下，即使用内积来代表pij：

![img](https:////upload-images.jianshu.io/upload_images/4155986-2ac2cd7b351795d8.png?imageMogr2/auto-orient/strip|imageView2/2/w/344/format/webp)

所以，pij其实是一个数，得到一个pij的时间复杂度为M，p的大小为N*N，因此计算得到p的时间复杂度为N*N*M。而再由p得到lp的时间复杂度是N*N*D1。因此 对于IPNN来说，总的时间复杂度为N*N(D1+M)。文章对这一结构进行了优化，可以看到，我们的p是一个对称矩阵，因此我们的权重也可以是一个对称矩阵，对称矩阵就可以进行如下的分解：

![img](https:////upload-images.jianshu.io/upload_images/4155986-69309c37e2b2ba70.png?imageMogr2/auto-orient/strip|imageView2/2/w/186/format/webp)

因此：

![img](https:////upload-images.jianshu.io/upload_images/4155986-3fce559f6e92c043.png?imageMogr2/auto-orient/strip|imageView2/2/w/860/format/webp)

![img](https:////upload-images.jianshu.io/upload_images/4155986-a4ab3900deca2373.png?imageMogr2/auto-orient/strip|imageView2/2/w/170/format/webp)

因此：

![img](https:////upload-images.jianshu.io/upload_images/4155986-4ddc93512149a560.png?imageMogr2/auto-orient/strip|imageView2/2/w/788/format/webp)

从而得到：

![img](https:////upload-images.jianshu.io/upload_images/4155986-5e75fafe9e0d9a14.png?imageMogr2/auto-orient/strip|imageView2/2/w/1016/format/webp)

可以看到，我们的权重只需要D1 * N就可以了，时间复杂度也变为了D1*M*N。

#### OPNN

OPNN的示意图如下：

![img](https:////upload-images.jianshu.io/upload_images/4155986-d9924e3ef896dc31.png?imageMogr2/auto-orient/strip|imageView2/2/w/756/format/webp)

OPNN中p的计算方式如下：




$$
P_{i,j}=g(f_i,f_j)=f_if_j^T
$$


此时pij为M*M的矩阵，计算一个pij的时间复杂度为M*M，而p是N*N*M*M的矩阵，因此计算p的事件复杂度为N*N*M*M。从而计算lp的时间复杂度变为D1 * N*N*M*M。这个显然代价很高的。为了减少负责度，论文使用了叠加的思想，它重新定义了p矩阵：

![img](https:////upload-images.jianshu.io/upload_images/4155986-a66fbf3c57b4d1ab.png?imageMogr2/auto-orient/strip|imageView2/2/w/956/format/webp)





### 核心代码

#### **Embedding Layer**

```python
# Embeddings
self.embeddings = tf.nn.embedding_lookup(self.weights['feature_embeddings'],self.feat_index) # N * F * K
feat_value = tf.reshape(self.feat_value,shape=[-1,self.field_size,1])
self.embeddings = tf.multiply(self.embeddings,feat_value) # N * F * K
```

#### **Product Layer**

```python
# Linear Singal
linear_output = []
for i in range(self.deep_init_size):
    linear_output.append(tf.reshape(
        tf.reduce_sum(tf.multiply(self.embeddings,self.weights['product-linear'][i]),axis=[1,2]),shape=(-1,1)))# N * 1

self.lz = tf.concat(linear_output,axis=1) # N * init_deep_size

# Quardatic Singal
quadratic_output = []
if self.use_inner:
    for i in range(self.deep_init_size):
        theta = tf.multiply(self.embeddings,tf.reshape(self.weights['product-quadratic-inner'][i],(1,-1,1))) # N * F * K
        quadratic_output.append(tf.reshape(tf.norm(tf.reduce_sum(theta,axis=1),axis=1),shape=(-1,1))) # N * 1

else:
    embedding_sum = tf.reduce_sum(self.embeddings,axis=1)
    p = tf.matmul(tf.expand_dims(embedding_sum,2),tf.expand_dims(embedding_sum,1)) # N * K * K
    for i in range(self.deep_init_size):
        theta = tf.multiply(p,tf.expand_dims(self.weights['product-quadratic-outer'][i],0)) # N * K * K
        quadratic_output.append(tf.reshape(tf.reduce_sum(theta,axis=[1,2]),shape=(-1,1))) # N * 1

self.lp = tf.concat(quadratic_output,axis=1) # N * init_deep_size

self.y_deep = tf.nn.relu(tf.add(tf.add(self.lz, self.lp), self.weights['product-bias']))
self.y_deep = tf.nn.dropout(self.y_deep, self.dropout_keep_deep[0])
```





### 训练结果

。![image-20201025172106967](D:\MarkDown\DeepLearning\img\image-20201025172106967.png)

![image-20201025172140232](D:\MarkDown\DeepLearning\img\image-20201025172140232.png)