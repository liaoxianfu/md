本周阅读论文《Deep Interest Network for Click-Through Rate Prediction》。本篇文章将深度学习运用在点击率转换预测上，解决了传统推荐中系统用户的不同兴趣被压缩成一个固定长度的向量，限制Embedding和MLP方法的表达能力的问题。



### 摘要



目前深度学习已经运用在点击率预测上了，在这些方法中，首先将大规模稀疏输入特征映射到低维嵌入向量中，然后按照分组方式变换为定长向量，最后连接在一起馈入多层感知器（MLP）以学习非线性关系 特征。 通过这种方式，无论候选广告是什么，用户特征都被压缩成一个固定长度的表示向量。但是使用定长的向量会带来瓶颈，这将会使 Embedding&MLP方法从历史信息中捕获用户的多样化的兴趣带来困难。本文提出了DIN模型，可以(1)使用兴趣分布代表用户多样化的兴趣（不同用户对不同商品有兴趣）(2)与attention机制一样，根据ad局部激活用户兴趣相关的兴趣（用户有很多兴趣，最后导致购买的是小部分兴趣，仅仅取决于历史行为数据中的一小部分，而不是全部。attention机制就是保留并激活这部分兴趣）。在输入层增加了激活单元。

该表示向量随广告的不同而不同，极大地提高了模型的表达能力。此外，作者还开发了两种技术：小批量感知正则化和数据自适应激活函数，可以帮助训练具有数亿个参数的工业深层网络。在两个公共数据集以及阿里巴巴超过20亿个样本的实际生产数据集上的实验证明了所提出的方法的有效性，与最先进的方法相比，这些方法取得了优越的性能。DIN现在已经成功部署在阿里巴巴的在线展示广告系统中，服务于主要产品上。

### 介绍



在CPC(Cost-per-Click)广告系统中，广告是按照投标价与点击率(CTR)的乘积--有效成本(Efficient Cost Per  Mille，eCPM)进行排序的，点击率需要由系统进行预测。因此，CTR预测模型的性能直接影响到最终的收益，在整个广告系统中起着至关重要的作用。建立CTR预测模型受到了学术界和产业界的广泛关注。

受计算机视觉和自然语言处理中深度学习的成功启发，基于深度学习的方法被提出用于CTR预测任务这些方法遵循相似的MLP范式：首先将大规模稀疏输入特征映射到低维嵌入向量，然后以分组的方式转化为固定长度的向量，最后级联在一起馈送到完全连通的层(也称为多层感知器，MLP)，以学习特征之间的非线性关系。与常用的Logistic回归模型[19]相比，这些深度学习方法可以减少大量的特征工程工作，大大提高模型的性能。为简单起见，本文将这些方法命名为Embedding&MLP，它们现在已经成为CTR预测任务中的热门方法。

然而用户兴趣是多样的。在CTR预测任务中，用户兴趣通常是从用户行为数据中获取的。嵌入&MLP方法通过将用户行为的嵌入向量变换为一个固定长度的向量来学习某个用户的所有兴趣的表示，该向量位于所有用户的表示向量所在的欧几里德空间中。换言之，用户的不同兴趣被压缩成一个固定长度的向量，这限制了嵌入和MLP方法的表达能力。为了使表示足够表达用户的不同兴趣，需要对定长向量的维数进行很大程度的扩展。不幸的是，这将大大扩大学习参数的规模，并加剧有限数据下的过拟合风险。此外，它增加了计算和存储的负担，这对于工业在线系统来说可能是不能容忍的。另一方面，当预测候选广告时，没有必要将特定用户的所有不同兴趣压缩成相同的向量，因为只有部分用户兴趣会影响他/她的动作(点击或不点击)。

作者提出的模型深度兴趣网络(DIN)，该模型通过考虑候选广告的历史行为的相关性，自适应地计算用户兴趣的表示向量。通过引入局部激活单元，DIN通过软搜索历史行为的相关部分来关注相关的用户兴趣，并采用加权和汇集来获得关于候选广告的用户兴趣表示。与候选广告相关性较高的行为会获得较高的激活权重，并主导用户兴趣的表示。作者在实验部分将这一现象形象化。



### 本文贡献

* 指出了固定长度向量表示用户兴趣的局限性，设计了一种新的深度兴趣网络(DIN)可以大大提高模型的表达能力，更好地捕捉用户兴趣的多样性特征。
* 开发了两种新的技术来帮助训练工业深层网络：i)小批量感知正则化，它省去了大量参数的深层网络上的大量正则化计算，有助于避免过拟合；ii)数据自适应激活函数，它通过考虑输入的分布来推广PReLU，并显示出良好的性能。
* 在公共数据集和阿里巴巴数据集上进行了广泛的实验。结果验证了所提出的数据挖掘和训练技术的有效性。



## DIN网络模型

本文提出DIN模型，同时对Diversity和Local Activation进行建模。

- Diversity：针对用户广泛的兴趣，DIN用an interest distribution去表示。
- Local Activation：历史行为中部分数据主导是否会点击候选广告。DIN借鉴机器翻译中的Attention机制，设计了一种attention-like network structure， 针对当前候选Ad，去局部的激活(Local Activate)相关的历史兴趣信息。和当前候选Ad相关性越高的历史行为，会获得更高的attention score，从而会主导这一次预测。能够很好的捕获用户兴趣的多样性特征。



CTR中输入普遍存在的特点：

- 高纬度
- 高度稀疏
- 多值离散特征(涉及到用户行为数据，例如访问多个不同的商品id等)



用户购买过的good_id有多个，购买过的shop_id也有多个，而这也直接导致了每个用户的历史行为id长度是不同的。针对多值离散特征，为了得到一个固定长度的Embedding Vector表示，原来的做法是在Embedding Layer后面增加一个Pooling Layer。Pooling可以用sum或average。最终得到一个固定长度的Embedding Vector，是用户兴趣的一个抽象表示，常被称作User Representation。缺点是会损失一些信息。DIN使用Attention机制来解决这个问题。在DIN场景中，针对不同的候选广告需要自适应地调整User Representation。也就是说：在Embedding Layer -> Pooling Layer得到用户兴趣表示的时候，赋予不同的历史行为不同的权重，实现局部激活。

## **Feature Representation**

把特征分为四大类：

![image-20200906162107044](D:\MarkDown\DeepLearning\img\image-20200906162107044.png)



提出的网络模型如下：

左边部分说明了基本模型(Embedding&MLP)的网络。将同属一个商品的Cate_id、shop_id和Goods_id的嵌入串联起来表示用户行为中的一个被访问商品。右边是作者提出的DIN模型。它引入了一个局部激活单元，可以根据不同的候选广告自适应地改变用户兴趣的表示。

![image-20200906162203001](D:\MarkDown\DeepLearning\img\image-20200906162203001.png)



具体 左边部分：

![image-20200906162253663](D:\MarkDown\DeepLearning\img\image-20200906162253663.png)



右边部分

![image-20200906162324907](D:\MarkDown\DeepLearning\img\image-20200906162324907.png)

通过Embedding进行连接



模型损失函数定义如下：

![image-20200906162448692](D:\MarkDown\DeepLearning\img\image-20200906162448692.png)



#### 小批量感知正则化

##### 1、PReLU

![image-20200906162619309](D:\MarkDown\DeepLearning\img\image-20200906162619309.png)

PReLu公式

![image-20200906162900475](D:\MarkDown\DeepLearning\img\image-20200906162900475.png)

PReLU取一个值为0的硬整流点，当每层的输入遵循不同的分布时，这可能不合适。考虑到这一点，作者设计了一种新颖的数据自适应激活函数DICE

![image-20200906162958364](D:\MarkDown\DeepLearning\img\image-20200906162958364.png)



#### 2、实验结果

Amazon数据集和MovieLens数据集的Model Coparison。所有行分别通过与每个数据集的BaseModel进行比较来计算RelaImpr。

![image-20200906163113597](D:\MarkDown\DeepLearning\img\image-20200906163113597.png)

不同规则化的BaseModel在阿里巴巴数据集上的最佳AUC。所有其他行通过与第一行进行比较来计算RelaImpr。

![image-20200906163205494](D:\MarkDown\DeepLearning\img\image-20200906163205494.png)

训练过程

不同正则化的BaseModel在阿里巴巴数据集上的性能。在没有正则化的情况下，使用细粒度的дOODS_IDS特征进行训练在第一个时代之后会遇到严重的过拟合。所有的正则化都有改进，其中作者提出的小批量感知正则化效果最好。此外，具有дOODS_IDS特征的训练有素的模型比没有这些特征的模型获得更高的AUC值。它来自细粒度功能包含的更丰富的信息。

![image-20200906163226339](D:\MarkDown\DeepLearning\img\image-20200906163226339.png)